{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "\n",
    "# Directory containing the partial .parquet files\n",
    "directory = \"/mnt/carpedkm_data/image_gen_ds/relaion2B-en-research\"\n",
    "\n",
    "# List all .snappy.parquet files\n",
    "parquet_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".snappy.parquet\")]\n",
    "\n",
    "# # Merge the partial files into one\n",
    "# tables = [pq.read_table(f) for f in parquet_files]\n",
    "# combined_table = pa.concat_tables(tables)\n",
    "\n",
    "# # Write the combined table to a new file\n",
    "# pq.write_table(combined_table, \"merged_file.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(parquet_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'similarity', 'hash', 'pwatermark', 'punsafe', 'caption', 'key',\n",
      "       'status', 'error_message', 'width', 'height', 'original_width',\n",
      "       'original_height', 'exif', 'md5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size: 13115819\n"
     ]
    }
   ],
   "source": [
    "# Example: Filter for safe images with no watermark\n",
    "filtered_df = df[(df['punsafe'] < 0.5) & (df['pwatermark'] < 0.5)]\n",
    "print(f\"Filtered dataset size: {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = filtered_df['url'].tolist()[:1000]  # Example: Limit to 1000 images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100_000\u001b[39m  \u001b[38;5;66;03m# Example chunk size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), chunk_size)):\n\u001b[0;32m----> 3\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     chunk_df\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/pandas/core/indexing.py:1178\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 1178\u001b[0m     \u001b[43mcheck_dict_or_set_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(key) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[1;32m   1180\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m is_iterator(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n",
      "File \u001b[0;32m/opt/conda/envs/ptca/lib/python3.10/site-packages/pandas/core/indexing.py:2770\u001b[0m, in \u001b[0;36mcheck_dict_or_set_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_dict_or_set_indexers\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2766\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2767\u001b[0m \u001b[38;5;124;03m    Check if the indexer is or contains a dict or set, which is no longer allowed.\u001b[39;00m\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m-> 2770\u001b[0m         \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2771\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2772\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2773\u001b[0m     ):\n\u001b[1;32m   2774\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2775\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a set as an indexer is not supported. Use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2776\u001b[0m         )\n\u001b[1;32m   2778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2779\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2780\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2781\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2782\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunk_size = 100_000  # Example chunk size\n",
    "for i, chunk in enumerate(range(0, len(df), chunk_size)):\n",
    "    chunk_df = df.iloc[chunk:chunk + chunk_size]\n",
    "    chunk_df.to_parquet(f\"chunk_{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crcmod\n",
    "import binascii\n",
    "\n",
    "# Compute and verify CRC for a .parquet file\n",
    "def verify_crc(parquet_file, crc_file):\n",
    "    crc32_func = crcmod.predefined.mkCrcFun('crc-32')\n",
    "    with open(parquet_file, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        calculated_crc = crc32_func(file_data)\n",
    "\n",
    "    with open(crc_file, \"rb\") as f:\n",
    "        stored_crc = int(f.read().strip(), 16)  # CRC values are often in hexadecimal\n",
    "\n",
    "    return calculated_crc == stored_crc\n",
    "\n",
    "# Example\n",
    "parquet_file = \"partial_file.snappy.parquet\"\n",
    "crc_file = \"partial_file.snappy.parquet.crc\"\n",
    "if verify_crc(parquet_file, crc_file):\n",
    "    print(f\"{parquet_file} is valid.\")\n",
    "else:\n",
    "    print(f\"{parquet_file} is corrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crcmod\n",
    "import binascii\n",
    "\n",
    "# Compute and verify CRC for a .parquet file\n",
    "def verify_crc(parquet_file, crc_file):\n",
    "    crc32_func = crcmod.predefined.mkCrcFun('crc-32')\n",
    "    with open(parquet_file, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        calculated_crc = crc32_func(file_data)\n",
    "\n",
    "    with open(crc_file, \"rb\") as f:\n",
    "        stored_crc = int(f.read().strip(), 16)  # CRC values are often in hexadecimal\n",
    "\n",
    "    return calculated_crc == stored_crc\n",
    "\n",
    "# Example\n",
    "parquet_file = \"partial_file.snappy.parquet\"\n",
    "crc_file = \"partial_file.snappy.parquet.crc\"\n",
    "if verify_crc(parquet_file, crc_file):\n",
    "    print(f\"{parquet_file} is valid.\")\n",
    "else:\n",
    "    print(f\"{parquet_file} is corrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pq.read_table(\"merged_file.snappy.parquet\")\n",
    "print(table.to_pandas())  # Convert to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"merged_file.snappy.parquet\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
